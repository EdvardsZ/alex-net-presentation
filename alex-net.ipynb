{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec97626",
   "metadata": {},
   "source": [
    "# ImageNet Classification with Deep Convolutional Neural Networks\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "\n",
    "### Context\n",
    "\n",
    "* ML machine methods of that time work well for relatvely small datasets. ( NORB, Caltech, Cifar )\n",
    "* Until very recently larger datasets emerge like ImageNet, LabelMe\n",
    "* Existing methods do not work well on these large datasets\n",
    "* To learn about thousands of objects of millions of images a model with large learning capacity is needed.\n",
    "\n",
    "### CNN's before this:\n",
    "* CNN's have much fewer parameters so they are easier to train\n",
    "* CNN's good performance for the number of parameters they have.\n",
    "* Expensive to apply to large scale images, because there is no effective implementation.\n",
    "* Highly optimized GPU implementation provided shown in the paper.\n",
    "\n",
    "### Specific contributions:\n",
    "\n",
    "* Achieved at that time best results on subsets of ImageNet used in the ILSVRC-2010 and ILSVRC-2012\n",
    "* One of the largest conventional neural networks at that time.\n",
    "* Highly optimized GPU implementation for CNNs.\n",
    "* Number of new and unusual features of network which improve the result.\n",
    "* Techniques to avoid overfitting.\n",
    "* Final network consists of five convolutional and three fully connected layers.\n",
    "* Fully utilized 2x Nvidia GTX 580 3GB GPUs\n",
    "\n",
    "----\n",
    "\n",
    "## 2. Dataset\n",
    "\n",
    "Large dataset with many labeeeeeels\n",
    "\n",
    "## 3. The architecture\n",
    "\n",
    "<img src=\"pinecone-image.png\" alt=\"Architecture diagram\" width=\"800\">\n",
    "\n",
    "Here are novel or unusual features of this netork described by the paper:\n",
    "\n",
    "### ReLU Nonlinearity\n",
    "\n",
    "<div style=\"overflow: auto;\">\n",
    "<img src=\"relu.png\" alt=\"ReLU diagram\" width=\"300\" style=\"float: right; margin-top: 20px; margin-left: 20px; margin-bottom: 10px;\">\n",
    "\n",
    "* AlexNet popularized the use of ReLus for Deep CNNs\n",
    "* Trains faster, which was demonstraded on CIFAR Dataset.\n",
    "* Contrast with prior work:\n",
    "    * Previous works used instead: $ f (x) = tanh(x)$ or $f (x) = (1 + e^{−x})^{−1}$, or $(x)=|tanh(x)|$\n",
    "    * Focused on regularization instead of fitting large datasets\n",
    "\n",
    "</div>\n",
    "\n",
    "### Training on 2 GPUs\n",
    "\n",
    "* GPUs had ~ 3gb memory which limits the size of networks\n",
    "* The network was split into two gpus\n",
    "* GPUs communicate only in certain layers, half parameters on each GPU.\n",
    "* Faster to train than on one GPU\n",
    "* Made use of NVIDIA CUDA framework\n",
    "\n",
    "### Local Response Normalization\n",
    "\n",
    "$$\n",
    "b^{i}_{x,y} =\n",
    "\\frac{a^{i}_{x,y}}\n",
    "{\\left(\n",
    "k + \\alpha\n",
    "\\sum_{j=\\max(0,\\, i - \\frac{n}{2})}^{\\min(N - 1,\\, i + \\frac{n}{2})}\n",
    "\\left(a^{j}_{x,y}\\right)^2\n",
    "\\right)^{\\beta}}\n",
    "$$\n",
    "\n",
    "What each term means:\n",
    "* $b^{i}_{x,y}$ activation after normalization\n",
    "* $a^{i}_{x,y}$ feature map after convolution and ReLu\n",
    "* $i$ feature map index\n",
    "* $j$ neigbouring feature map index\n",
    "* $x,y$ fixed pixel in the feature map\n",
    "* $k$ Baseline numerical stabilizer\n",
    "* $\\sum_{j=\\max(0,\\, i - \\frac{n}{2})}^{\\min(N - 1,\\, i + \\frac{n}{2})}\n",
    "\\left(a^{j}_{x,y}\\right)^2$ - Measures how strong nearby filters are at x,y\n",
    "* $\\alpha\\beta $ Normalization strenth - scales the influence of neighbours, Beta controls the how much non linear the suppresion is.\n",
    "----\n",
    "* Batch Normalization is more effective\n",
    "* LRN adds computational cost.\n",
    "* Benefits do not scale to even deeper networks.\n",
    "\n",
    "### Overlapping pooling\n",
    "\n",
    "<img src=\"maxpooling.png\" alt=\"ReLU diagram\" width=\"300\">\n",
    "\n",
    "* summaraizes local neighborhoods within a feature map\n",
    "* AlexNet used overlapping pooling window size 3*3, stride = 2\n",
    "* Slightly harder to overfit\n",
    "* Reduced error 0.4%\n",
    "\n",
    "----\n",
    "\n",
    "## 4. Reducing overfittting\n",
    "\n",
    "* Even though dataset has 1000 classes, 60 million parameters of model make it easy to overfit.\n",
    "\n",
    "### Data augmentation\n",
    "\n",
    "* Easiest way reduce overfitting as described in paper.\n",
    "* Augmentations:\n",
    "    * Image translations and horizontal reflections. ( Random patches 224x224 from 256x256)\n",
    "    * Color PCA for each pixel $I_{xy} = [R, G, B]^T$, add:\n",
    "    \n",
    "    $$ [p_1, p_2, p_3] \\cdot [\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T $$\n",
    "    \n",
    "    Where:\n",
    "    * $p_i$ = $i$-th eigenvector of RGB covariance\n",
    "    * $\\lambda_i$ = $i$-th eigenvalue\n",
    "    * $\\alpha_i$ = Gaussian random variable, re-drawn per image\n",
    "    \n",
    "    **Why this works:**\n",
    "    * Captures principal axes of variation in natural lighting/colors\n",
    "    * Introduces realistic color shifts without changing object identity\n",
    "    * Helps generalization for large-scale datasets like ImageNet\n",
    "\n",
    "### Dropout\n",
    "\n",
    "* Sets each hidden neuron to zero with probability 0.5 during training\n",
    "* Reduces co-adaptations - forces learning of robust features\n",
    "* Used in first two fully-connected layers\n",
    "* Prevents substantial overfitting\n",
    "\n",
    "----\n",
    "\n",
    "## 5. Details of learning\n",
    "\n",
    "* **Optimizer:** Stochastic gradient descent (batch size: 128, momentum: 0.9, weight decay: 0.0005)\n",
    "    \n",
    "    Update rule:\n",
    "    $$v_{i+1} := 0.9 \\cdot v_i - 0.0005 \\cdot \\epsilon \\cdot w_i - \\epsilon \\cdot \\left\\langle \\frac{\\partial L}{\\partial w}\\Big|_{w_i} \\right\\rangle_{D_i}$$\n",
    "    $$w_{i+1} := w_i + v_{i+1}$$\n",
    "    \n",
    "    Where:\n",
    "    * $i$ = iteration index\n",
    "    * $v_i$ = momentum variable (velocity)\n",
    "    * $w_i$ = weights at iteration $i$\n",
    "    * $\\epsilon$ = learning rate\n",
    "    * $0.9$ = momentum coefficient\n",
    "    * $0.0005$ = weight decay coefficient\n",
    "    * $\\left\\langle \\frac{\\partial L}{\\partial w}\\Big|_{w_i} \\right\\rangle_{D_i}$ = average gradient over batch $D_i$\n",
    "\n",
    "* **Weight initialization:** Zero-mean Gaussian, std = 0.01\n",
    "* **Bias initialization:**\n",
    "    * Constant 1: Conv layers 2, 4, 5 and FC layers (helps ReLUs)\n",
    "    * Constant 0: All other layers\n",
    "* **Learning rate:** Started at 0.01, reduced by 10x when validation error plateaued\n",
    "* **Training:** 90 epochs, 5-6 days on 2x NVIDIA GTX 580 GPUs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785851ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82130149",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7699f11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "562716eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "652a83ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab8ba9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2856cf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb1be458",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c2dec3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6c06555",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3529a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
